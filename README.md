Here is a formatted `README.md` ready for your GitHub repository. I have organized it with clear headers, code blocks, and tables to ensure it looks professional and is easy to navigate.

-----

# ðŸ›¡ï¸ LLM Red Teaming & Adversarial Evaluation Suite

This repository contains a comprehensive corpus of Large Language Model (LLM) attack vectors and a Python test harness designed to evaluate model robustness. The suite covers a wide spectrum of techniques, ranging from basic prompt injection to advanced cryptographic, logical, and mathematical exploits (including GCG attacks).

## ðŸ“‚ Repository Contents

| File Name | Description |
| :--- | :--- |
| **`01_attack_corpus_en.json`** | A JSON Lines dataset containing over **60 distinct attack vectors** (English), including persona modulation, logic locks, and obfuscation techniques. |
| **`02_attack_corpus_th.json`** | A JSON dataset containing **75 attack vectors adapted for Thai language context**, addressing cultural nuances and multilingual tokenization vulnerabilities. |
| **`03_red_team_runner.py`** | The main evaluation script for executing English attack vectors against target LLMs. |
| **`04_red_team_runner_thai.py`** | A specialized evaluation script handling Thai language nuances, encoding issues, and specific API behavior for non-Latin scripts. |
| **`05_indirect_red_team.py`** | A simulation script for **Indirect Prompt Injection** attacks (e.g., via poisoned emails, documents, or RAG contexts). |
| **`06_defense_runner.py`** | An implementation of the **"Sandwich Defense"** pattern to demonstrate mitigation strategies against the included attacks. |

## ðŸš€ Getting Started

### Prerequisites

Ensure you have Python installed, then install the required dependencies:

```bash
pip install openai
```

### Configuration

Set your OpenAI API key as an environment variable to allow the runners to query the models:

**Mac/Linux:**

```bash
export OPENAI_API_KEY='sk-...'
```

**Windows (PowerShell):**

```powershell
$env:OPENAI_API_KEY='sk-...'
```

## âš”ï¸ Usage

### 1\. Run Standard Red Teaming (English)

Execute the main runner to test the English corpus against your specified model:

```bash
python red_team_runner.py
```

### 2\. Run Multilingual Red Teaming (Thai)

Execute the specialized runner for Thai language attack vectors:

```bash
python red_team_runner_thai.py
```

### 3\. Analyze Results

After execution, the scripts will generate `.csv` files in the output directory. Open these files to view:

  * **Pass/Fail Assessments:** Did the model refuse the attack or comply?
  * **Response Logs:** The exact output generated by the model.
  * **Attack Category:** Which specific technique (e.g., GCG, Payload Splitting) caused the failure.

-----

## âš ï¸ Disclaimer

> **Educational and Research Purpose Only**
>
> This dataset and code are provided solely for educational purposes and security research. The intent is to help developers, researchers, and organizations identify weaknesses in their own AI systems to improve safety and alignment.
>
> The authors do not endorse or encourage the use of these techniques for malicious purposes. Users are responsible for ensuring their testing activities comply with applicable laws and terms of service of the API providers.
